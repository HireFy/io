一个job运行的时候，会首先创建一个`Source`实例，这个`Source`实例会创建一个`WorkUnit`集合，通常这个集合中的每一个`WorkUnit`会创建一个`task`，`MultiWorkUnit`例外。

当`Source`创建`WorkUnit`的时候，每个`WorkUnit`通常都包含一个low watermark和一个expected high watermark，这两个是对应的task的运行的起点和终点，在运行的时候，task要从low watermark一直获取数据直到expected high watermark。

job在运行的时候，当一个task完成提取数据的操作后，会把实际的high watermark写到他的`WorkUnitState`，下一个task运行的时候，就会直到上次运行的状况。

现在在gobblin里面，存储state的实现是使用Haddoop SequenceFiles 来存储，默认情况下，job会读取上次运行创建的SequenceFile。然后生成新的SequenceFile。这样的话就可能会造成一个隐藏的陷阱，如果一个dataset由于各种各样的原因被跳过了，那么它的watermark将在下次运行的时候不可用

文档中举了个例子，当gobblin要从一个含有10个partition的Kafka broker中pull一个topic的时候，这样一个partition就可以看作是一个dataset，如果在运行的时候其中一个partition由于某种原因被跳过了，那么这个dataset的watermark就不会被创建，然后在state store里也不会有相关的存储，下次运行的时候也不会找到这个dataset，这条dataset的数据将永远丢失

所以在这里使用dataset URN，当一个job从多个dataset里pull data的时候，`Source`将为每个dataset定义一个URN。eg. 上面那个例子的topic的第5个partition，可以用`PageViewEvent.5`作为它的URN。当`Source`创建`WorkUnit`的时候，`Source`会为这个`WorkUnit`设置属性`dataset.urn`为`PageViewEvent.5`。这样的话每个`WorkUnit`都有不同的`dataset.urn`的值，然后job会为每个`dataset.urn`创建一个state store SequenceFile，在下次运行的时候，就会调用`SourceState.getPreviousWorkUnitStatesByDatasetUrns()`，而不是普通的调用`SourceState.getPreviousWorkUnitStates()`，这样即使有一个dataset没有被job处理，它的watermark也不会丢失，下次运行的时候它就会被找到并处理。

每个`WorkUnit`只能有一个`dataset.urn`，而一个`dataset.urn`可能会有很多个`WorkUnit`。

使用URN，是gobblin目前用来支持job能从多个dataset提取数据的方法
